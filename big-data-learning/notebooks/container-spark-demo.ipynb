{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å®¹å™¨ç¯å¢ƒ Spark å¼€å‘æ¼”ç¤º\n",
    "\n",
    "è¿™ä¸ª notebook æ¼”ç¤ºå¦‚ä½•åœ¨å®¹å™¨åŒ–ç¯å¢ƒä¸­ä½¿ç”¨ PySpark è¿›è¡Œå¼€å‘ã€‚\n",
    "\n",
    "## ç¯å¢ƒä¿¡æ¯\n",
    "- è¿è¡Œç¯å¢ƒ: Docker å®¹å™¨\n",
    "- Spark é›†ç¾¤: spark://spark-master:7077\n",
    "- Python åŒ…: ä½¿ç”¨å›½å†…é•œåƒæºåŠ é€Ÿå®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"Python ç‰ˆæœ¬: {sys.version}\")\n",
    "print(f\"å½“å‰æ—¶é—´: {datetime.now()}\")\n",
    "print(f\"å·¥ä½œç›®å½•: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨é¢„é…ç½®çš„ PySpark åˆå§‹åŒ–å‡½æ•°\n",
    "exec(open('/opt/bitnami/spark/notebooks/pyspark_init.py').read())\n",
    "\n",
    "# åˆ›å»º Spark ä¼šè¯\n",
    "spark = create_spark_session(\"ContainerSparkDemo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºç¤ºä¾‹æ•°æ®\n",
    "data = [\n",
    "    (1, \"å¼ ä¸‰\", 25, \"åŒ—äº¬\"),\n",
    "    (2, \"æå››\", 30, \"ä¸Šæµ·\"),\n",
    "    (3, \"ç‹äº”\", 35, \"å¹¿å·\"),\n",
    "    (4, \"èµµå…­\", 28, \"æ·±åœ³\"),\n",
    "    (5, \"é’±ä¸ƒ\", 32, \"æ­å·\")\n",
    "]\n",
    "\n",
    "columns = [\"id\", \"name\", \"age\", \"city\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "print(\"ğŸ“Š åˆ›å»ºçš„ DataFrame:\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame åŸºæœ¬æ“ä½œ\n",
    "print(\"ğŸ“ˆ DataFrame åŸºæœ¬ä¿¡æ¯:\")\n",
    "print(f\"è¡Œæ•°: {df.count()}\")\n",
    "print(f\"åˆ—æ•°: {len(df.columns)}\")\n",
    "print(f\"åˆ—å: {df.columns}\")\n",
    "\n",
    "print(\"\\nğŸ“‹ Schema ä¿¡æ¯:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®è¿‡æ»¤å’Œè½¬æ¢\n",
    "from pyspark.sql.functions import col, avg, max, min\n",
    "\n",
    "# è¿‡æ»¤å¹´é¾„å¤§äº 30 çš„è®°å½•\n",
    "older_people = df.filter(col(\"age\") > 30)\n",
    "print(\"ğŸ” å¹´é¾„å¤§äº 30 çš„äººå‘˜:\")\n",
    "older_people.show()\n",
    "\n",
    "# è®¡ç®—ç»Ÿè®¡ä¿¡æ¯\n",
    "stats = df.agg(\n",
    "    avg(\"age\").alias(\"å¹³å‡å¹´é¾„\"),\n",
    "    max(\"age\").alias(\"æœ€å¤§å¹´é¾„\"),\n",
    "    min(\"age\").alias(\"æœ€å°å¹´é¾„\")\n",
    ")\n",
    "\n",
    "print(\"ğŸ“Š å¹´é¾„ç»Ÿè®¡:\")\n",
    "stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ Spark SQL\n",
    "df.createOrReplaceTempView(\"people\")\n",
    "\n",
    "# SQL æŸ¥è¯¢\n",
    "sql_result = spark.sql(\"\"\"\n",
    "    SELECT city, COUNT(*) as count, AVG(age) as avg_age\n",
    "    FROM people \n",
    "    GROUP BY city\n",
    "    ORDER BY avg_age DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"ğŸ™ï¸ æŒ‰åŸå¸‚ç»Ÿè®¡:\")\n",
    "sql_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®å¯è§†åŒ– (ä½¿ç”¨ matplotlib)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# è½¬æ¢ä¸º Pandas DataFrame è¿›è¡Œå¯è§†åŒ–\n",
    "pandas_df = df.toPandas()\n",
    "\n",
    "# åˆ›å»ºå¹´é¾„åˆ†å¸ƒå›¾\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(pandas_df['name'], pandas_df['age'])\n",
    "plt.title('å¹´é¾„åˆ†å¸ƒ')\n",
    "plt.xlabel('å§“å')\n",
    "plt.ylabel('å¹´é¾„')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "city_counts = pandas_df['city'].value_counts()\n",
    "plt.pie(city_counts.values, labels=city_counts.index, autopct='%1.1f%%')\n",
    "plt.title('åŸå¸‚åˆ†å¸ƒ')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ“ˆ æ•°æ®å¯è§†åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯»å–å¤–éƒ¨æ•°æ®æ–‡ä»¶ (å¦‚æœå­˜åœ¨)\n",
    "data_path = \"/opt/bitnami/spark/data\"\n",
    "print(f\"ğŸ“ æ•°æ®ç›®å½•å†…å®¹: {os.listdir(data_path)}\")\n",
    "\n",
    "# å°è¯•è¯»å– CSV æ–‡ä»¶ (å¦‚æœå­˜åœ¨)\n",
    "try:\n",
    "    # è¿™é‡Œå¯ä»¥è¯»å–ä½ æ”¾åœ¨ data/ ç›®å½•ä¸‹çš„æ–‡ä»¶\n",
    "    # csv_df = spark.read.csv(f\"{data_path}/your_file.csv\", header=True, inferSchema=True)\n",
    "    # csv_df.show(5)\n",
    "    print(\"ğŸ’¡ æç¤º: å°†ä½ çš„æ•°æ®æ–‡ä»¶æ”¾åœ¨ data/ ç›®å½•ä¸‹ï¼Œç„¶ååœ¨è¿™é‡Œè¯»å–\")\nexcept Exception as e:\n",
    "    print(f\"ğŸ“ æ³¨æ„: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é›†ç¾¤ä¿¡æ¯å’Œæ€§èƒ½ç›‘æ§\n",
    "sc = spark.sparkContext\n",
    "\n",
    "print(\"ğŸ–¥ï¸  Spark é›†ç¾¤ä¿¡æ¯:\")\n",
    "print(f\"  åº”ç”¨åç§°: {sc.appName}\")\n",
    "print(f\"  åº”ç”¨ ID: {sc.applicationId}\")\n",
    "print(f\"  Master URL: {sc.master}\")\n",
    "print(f\"  Spark ç‰ˆæœ¬: {sc.version}\")\n",
    "print(f\"  é»˜è®¤å¹¶è¡Œåº¦: {sc.defaultParallelism}\")\n",
    "\n",
    "# è·å– Executor ä¿¡æ¯\n",
    "executors = sc.statusTracker().getExecutorInfos()\n",
    "print(f\"  Executor æ•°é‡: {len(executors)}\")\n",
    "\n",
    "for executor in executors:\n",
    "    print(f\"    Executor {executor.executorId}: {executor.host}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸…ç†èµ„æº\n",
    "spark.stop()\n",
    "print(\"âœ… Spark ä¼šè¯å·²å…³é—­\")\n",
    "print(\"\\nğŸ‰ å®¹å™¨ç¯å¢ƒ Spark å¼€å‘æ¼”ç¤ºå®Œæˆï¼\")\n",
    "print(\"\\nğŸ’¡ ä¸‹ä¸€æ­¥:\")\n",
    "print(\"  1. æ¢ç´¢ notebooks/ ç›®å½•ä¸‹çš„å…¶ä»–æ•™ç¨‹\")\n",
    "print(\"  2. å°†ä½ çš„æ•°æ®æ–‡ä»¶æ”¾åœ¨ data/ ç›®å½•ä¸‹\")\n",
    "print(\"  3. å¼€å§‹ä½ çš„ Spark å­¦ä¹ é¡¹ç›®\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}