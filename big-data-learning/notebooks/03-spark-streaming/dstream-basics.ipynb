{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Streaming基础 - DStream API\n",
    "\n",
    "本笔记本介绍Spark Streaming的基础概念和DStream API的使用。Spark Streaming是Spark的一个扩展，用于处理实时数据流。\n",
    "\n",
    "## 什么是Spark Streaming？\n",
    "\n",
    "Spark Streaming是一个可扩展、高吞吐量、容错的流处理系统，它可以处理实时数据流。它将实时输入数据流分成批次，然后由Spark引擎处理，生成最终的结果流。\n",
    "\n",
    "### 核心概念\n",
    "\n",
    "- **DStream (Discretized Stream)**：离散化流，是Spark Streaming的基本抽象，表示连续的数据流\n",
    "- **批处理间隔**：将数据流分割成批次的时间间隔\n",
    "- **窗口操作**：在滑动时间窗口上进行计算\n",
    "- **检查点**：用于容错和恢复的机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 创建StreamingContext\n",
    "\n",
    "StreamingContext是Spark Streaming的主要入口点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "import time\n",
    "import threading\n",
    "import socket\n",
    "import random\n",
    "\n",
    "# 创建SparkContext\n",
    "conf = SparkConf().setAppName(\"DStream基础\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# 创建StreamingContext，批处理间隔为2秒\n",
    "ssc = StreamingContext(sc, 2)\n",
    "\n",
    "print(\"StreamingContext创建成功\")\n",
    "print(f\"批处理间隔: {ssc._batchDuration} 秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 创建DStream\n",
    "\n",
    "DStream可以从各种数据源创建，包括TCP套接字、文件系统、Kafka等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 从队列创建DStream（用于测试）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个队列用于模拟数据流\n",
    "import queue\n",
    "\n",
    "# 创建RDD队列\n",
    "rdd_queue = []\n",
    "\n",
    "# 创建一些示例数据\n",
    "for i in range(5):\n",
    "    rdd = sc.parallelize([f\"batch_{i}_item_{j}\" for j in range(10)])\n",
    "    rdd_queue.append(rdd)\n",
    "\n",
    "# 从队列创建DStream\n",
    "queue_stream = ssc.queueStream(rdd_queue, oneAtATime=True)\n",
    "\n",
    "print(\"从队列创建的DStream:\")\n",
    "queue_stream.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 从文本文件创建DStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个目录用于监控新文件\n",
    "import os\n",
    "streaming_dir = \"/home/jovyan/data/streaming\"\n",
    "os.makedirs(streaming_dir, exist_ok=True)\n",
    "\n",
    "# 从文件目录创建DStream\n",
    "file_stream = ssc.textFileStream(streaming_dir)\n",
    "\n",
    "print(f\"监控目录: {streaming_dir}\")\n",
    "print(\"文件流DStream创建成功\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 创建模拟数据生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个简单的数据生成器\n",
    "def generate_sample_data():\n",
    "    \"\"\"生成示例数据\"\"\"\n",
    "    products = ['laptop', 'phone', 'tablet', 'watch', 'headphones']\n",
    "    regions = ['North', 'South', 'East', 'West']\n",
    "    \n",
    "    data = []\n",
    "    for _ in range(10):\n",
    "        product = random.choice(products)\n",
    "        region = random.choice(regions)\n",
    "        price = random.randint(100, 1000)\n",
    "        timestamp = int(time.time())\n",
    "        data.append(f\"{timestamp},{product},{region},{price}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 测试数据生成器\n",
    "sample_data = generate_sample_data()\n",
    "print(\"示例数据:\")\n",
    "for item in sample_data[:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DStream转换操作\n",
    "\n",
    "DStream支持类似RDD的转换操作，如map、filter、reduce等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新创建StreamingContext用于演示\n",
    "if 'ssc' in locals():\n",
    "    ssc.stop(stopSparkContext=False)\n",
    "\n",
    "ssc = StreamingContext(sc, 2)\n",
    "\n",
    "# 创建测试数据队列\n",
    "test_queue = []\n",
    "for i in range(3):\n",
    "    data = generate_sample_data()\n",
    "    rdd = sc.parallelize(data)\n",
    "    test_queue.append(rdd)\n",
    "\n",
    "# 创建DStream\n",
    "lines = ssc.queueStream(test_queue, oneAtATime=True)\n",
    "\n",
    "print(\"原始数据流:\")\n",
    "lines.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map操作：解析CSV数据\n",
    "def parse_line(line):\n",
    "    parts = line.split(',')\n",
    "    if len(parts) == 4:\n",
    "        return {\n",
    "            'timestamp': int(parts[0]),\n",
    "            'product': parts[1],\n",
    "            'region': parts[2],\n",
    "            'price': int(parts[3])\n",
    "        }\n",
    "    return None\n",
    "\n",
    "parsed_stream = lines.map(parse_line).filter(lambda x: x is not None)\n",
    "\n",
    "print(\"解析后的数据流:\")\n",
    "parsed_stream.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter操作：过滤高价商品\n",
    "expensive_items = parsed_stream.filter(lambda x: x['price'] > 500)\n",
    "\n",
    "print(\"高价商品流:\")\n",
    "expensive_items.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatMap操作：展开数据\n",
    "product_stream = parsed_stream.flatMap(lambda x: [(x['product'], x['price'])])\n",
    "\n",
    "print(\"产品价格流:\")\n",
    "product_stream.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DStream输出操作\n",
    "\n",
    "输出操作将DStream的数据输出到外部系统。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint：打印到控制台\n",
    "parsed_stream.pprint(10)  # 打印每个批次的前10个元素\n",
    "\n",
    "# saveAsTextFiles：保存到文件\n",
    "output_dir = \"/home/jovyan/data/output/streaming\"\n",
    "parsed_stream.saveAsTextFiles(output_dir)\n",
    "\n",
    "# foreachRDD：自定义处理\n",
    "def process_rdd(rdd):\n",
    "    if not rdd.isEmpty():\n",
    "        count = rdd.count()\n",
    "        print(f\"处理了 {count} 条记录\")\n",
    "        \n",
    "        # 计算平均价格\n",
    "        if count > 0:\n",
    "            total_price = rdd.map(lambda x: x['price']).sum()\n",
    "            avg_price = total_price / count\n",
    "            print(f\"平均价格: {avg_price:.2f}\")\n",
    "\n",
    "parsed_stream.foreachRDD(process_rdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 有状态转换\n",
    "\n",
    "有状态转换允许您在多个批次之间维护状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置检查点目录（有状态操作需要）\n",
    "checkpoint_dir = \"/home/jovyan/data/checkpoint\"\n",
    "ssc.checkpoint(checkpoint_dir)\n",
    "\n",
    "# updateStateByKey：维护每个键的状态\n",
    "def update_function(new_values, running_count):\n",
    "    if running_count is None:\n",
    "        running_count = 0\n",
    "    return sum(new_values, running_count)\n",
    "\n",
    "# 计算每个产品的累计销售数量\n",
    "product_counts = product_stream.map(lambda x: (x[0], 1))\n",
    "running_counts = product_counts.updateStateByKey(update_function)\n",
    "\n",
    "print(\"产品累计销售数量:\")\n",
    "running_counts.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 窗口操作\n",
    "\n",
    "窗口操作允许您在滑动时间窗口上应用转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 窗口操作：在6秒的窗口内，每4秒计算一次\n",
    "windowed_stream = product_stream.window(6, 4)  # 窗口长度6秒，滑动间隔4秒\n",
    "\n",
    "print(\"窗口内的数据:\")\n",
    "windowed_stream.pprint()\n",
    "\n",
    "# 窗口内的聚合操作\n",
    "windowed_counts = product_stream.map(lambda x: (x[0], 1)).reduceByKeyAndWindow(\n",
    "    lambda x, y: x + y,  # 聚合函数\n",
    "    lambda x, y: x - y,  # 逆聚合函数（可选，用于优化）\n",
    "    6,  # 窗口长度\n",
    "    4   # 滑动间隔\n",
    ")\n",
    "\n",
    "print(\"窗口内产品计数:\")\n",
    "windowed_counts.pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 实际案例：实时销售监控\n",
    "\n",
    "让我们创建一个实时销售监控系统的示例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新创建StreamingContext用于完整示例\n",
    "if 'ssc' in locals():\n",
    "    ssc.stop(stopSparkContext=False)\n",
    "\n",
    "ssc = StreamingContext(sc, 3)  # 3秒批处理间隔\n",
    "ssc.checkpoint(\"/home/jovyan/data/checkpoint\")\n",
    "\n",
    "# 创建更多测试数据\n",
    "sales_queue = []\n",
    "for i in range(5):\n",
    "    data = generate_sample_data()\n",
    "    rdd = sc.parallelize(data)\n",
    "    sales_queue.append(rdd)\n",
    "\n",
    "# 创建销售数据流\n",
    "sales_stream = ssc.queueStream(sales_queue, oneAtATime=True)\n",
    "\n",
    "# 解析销售数据\n",
    "parsed_sales = sales_stream.map(parse_line).filter(lambda x: x is not None)\n",
    "\n",
    "print(\"实时销售监控系统启动...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 实时销售统计\n",
    "def calculate_sales_stats(rdd):\n",
    "    if not rdd.isEmpty():\n",
    "        sales_data = rdd.collect()\n",
    "        \n",
    "        total_sales = sum(item['price'] for item in sales_data)\n",
    "        total_items = len(sales_data)\n",
    "        avg_price = total_sales / total_items if total_items > 0 else 0\n",
    "        \n",
    "        print(f\"=== 批次销售统计 ===\")\n",
    "        print(f\"总销售额: ${total_sales}\")\n",
    "        print(f\"销售数量: {total_items}\")\n",
    "        print(f\"平均价格: ${avg_price:.2f}\")\n",
    "        print(\"=\" * 25)\n",
    "\n",
    "parsed_sales.foreachRDD(calculate_sales_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 按地区统计销售额\n",
    "region_sales = parsed_sales.map(lambda x: (x['region'], x['price']))\n",
    "region_totals = region_sales.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "print(\"按地区销售额:\")\n",
    "region_totals.pprint()\n",
    "\n",
    "# 3. 热门产品排行（窗口操作）\n",
    "product_sales = parsed_sales.map(lambda x: (x['product'], x['price']))\n",
    "windowed_product_sales = product_sales.reduceByKeyAndWindow(\n",
    "    lambda x, y: x + y,\n",
    "    9,  # 9秒窗口\n",
    "    3   # 3秒滑动\n",
    ")\n",
    "\n",
    "# 获取热门产品\n",
    "def get_top_products(rdd):\n",
    "    if not rdd.isEmpty():\n",
    "        top_products = rdd.takeOrdered(3, key=lambda x: -x[1])\n",
    "        print(\"=== 热门产品排行 ===\")\n",
    "        for i, (product, sales) in enumerate(top_products, 1):\n",
    "            print(f\"{i}. {product}: ${sales}\")\n",
    "        print(\"=\" * 25)\n",
    "\n",
    "windowed_product_sales.foreachRDD(get_top_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 异常检测：检测异常高价商品\n",
    "def detect_anomalies(rdd):\n",
    "    if not rdd.isEmpty():\n",
    "        sales_data = rdd.collect()\n",
    "        prices = [item['price'] for item in sales_data]\n",
    "        \n",
    "        if len(prices) > 1:\n",
    "            avg_price = sum(prices) / len(prices)\n",
    "            threshold = avg_price * 2  # 异常阈值：平均价格的2倍\n",
    "            \n",
    "            anomalies = [item for item in sales_data if item['price'] > threshold]\n",
    "            \n",
    "            if anomalies:\n",
    "                print(\"=== 异常检测 ===\")\n",
    "                print(f\"检测到 {len(anomalies)} 个异常高价商品:\")\n",
    "                for item in anomalies:\n",
    "                    print(f\"  {item['product']} - ${item['price']} (阈值: ${threshold:.2f})\")\n",
    "                print(\"=\" * 20)\n",
    "\n",
    "parsed_sales.foreachRDD(detect_anomalies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 启动和停止流处理\n",
    "\n",
    "配置完所有的转换和输出操作后，需要启动StreamingContext。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 启动流处理（注意：这会阻塞执行）\n",
    "print(\"启动流处理...\")\n",
    "print(\"处理5个批次后自动停止\")\n",
    "\n",
    "# 在实际应用中，您可能会使用 ssc.start() 和 ssc.awaitTermination()\n",
    "# 这里我们使用一个定时器来演示\n",
    "def stop_streaming():\n",
    "    time.sleep(15)  # 运行15秒\n",
    "    ssc.stop(stopSparkContext=False)\n",
    "    print(\"流处理已停止\")\n",
    "\n",
    "# 在后台线程中启动停止定时器\n",
    "stop_thread = threading.Thread(target=stop_streaming)\n",
    "stop_thread.start()\n",
    "\n",
    "# 启动流处理\n",
    "ssc.start()\n",
    "ssc.awaitTermination()\n",
    "\n",
    "print(\"流处理完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 练习\n",
    "\n",
    "现在，让我们通过一些练习来巩固所学知识。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习1：实时单词计数\n",
    "\n",
    "创建一个实时单词计数程序，统计文本流中每个单词的出现次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建新的StreamingContext\n",
    "ssc_word = StreamingContext(sc, 2)\n",
    "ssc_word.checkpoint(\"/home/jovyan/data/checkpoint_word\")\n",
    "\n",
    "# 创建文本数据\n",
    "text_data = [\n",
    "    \"hello world spark streaming\",\n",
    "    \"spark is great for big data\",\n",
    "    \"streaming data processing with spark\",\n",
    "    \"hello spark hello world\",\n",
    "    \"big data analytics with spark streaming\"\n",
    "]\n",
    "\n",
    "text_queue = []\n",
    "for text in text_data:\n",
    "    rdd = sc.parallelize([text])\n",
    "    text_queue.append(rdd)\n",
    "\n",
    "# 创建文本流\n",
    "text_stream = ssc_word.queueStream(text_queue, oneAtATime=True)\n",
    "\n",
    "# 实现单词计数\n",
    "words = text_stream.flatMap(lambda line: line.split(\" \"))\n",
    "word_pairs = words.map(lambda word: (word, 1))\n",
    "word_counts = word_pairs.reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# 维护累计单词计数\n",
    "def update_word_count(new_values, running_count):\n",
    "    if running_count is None:\n",
    "        running_count = 0\n",
    "    return sum(new_values, running_count)\n",
    "\n",
    "running_word_counts = word_pairs.updateStateByKey(update_word_count)\n",
    "\n",
    "print(\"实时单词计数:\")\n",
    "word_counts.pprint()\n",
    "\n",
    "print(\"累计单词计数:\")\n",
    "running_word_counts.pprint()\n",
    "\n",
    "# 启动并运行一段时间\n",
    "def stop_word_streaming():\n",
    "    time.sleep(10)\n",
    "    ssc_word.stop(stopSparkContext=False)\n",
    "\n",
    "stop_thread = threading.Thread(target=stop_word_streaming)\n",
    "stop_thread.start()\n",
    "\n",
    "ssc_word.start()\n",
    "ssc_word.awaitTermination()\n",
    "\n",
    "print(\"单词计数练习完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习2：网络流量监控\n",
    "\n",
    "模拟网络流量监控，检测异常流量模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成网络流量数据\n",
    "def generate_network_data():\n",
    "    ips = ['192.168.1.1', '192.168.1.2', '192.168.1.3', '10.0.0.1', '10.0.0.2']\n",
    "    actions = ['GET', 'POST', 'PUT', 'DELETE']\n",
    "    \n",
    "    data = []\n",
    "    for _ in range(20):\n",
    "        ip = random.choice(ips)\n",
    "        action = random.choice(actions)\n",
    "        bytes_sent = random.randint(100, 10000)\n",
    "        timestamp = int(time.time())\n",
    "        data.append(f\"{timestamp},{ip},{action},{bytes_sent}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# 创建StreamingContext\n",
    "ssc_network = StreamingContext(sc, 3)\n",
    "ssc_network.checkpoint(\"/home/jovyan/data/checkpoint_network\")\n",
    "\n",
    "# 创建网络数据流\n",
    "network_queue = []\n",
    "for i in range(4):\n",
    "    data = generate_network_data()\n",
    "    rdd = sc.parallelize(data)\n",
    "    network_queue.append(rdd)\n",
    "\n",
    "network_stream = ssc_network.queueStream(network_queue, oneAtATime=True)\n",
    "\n",
    "# 解析网络数据\n",
    "def parse_network_line(line):\n",
    "    parts = line.split(',')\n",
    "    if len(parts) == 4:\n",
    "        return {\n",
    "            'timestamp': int(parts[0]),\n",
    "            'ip': parts[1],\n",
    "            'action': parts[2],\n",
    "            'bytes': int(parts[3])\n",
    "        }\n",
    "    return None\n",
    "\n",
    "parsed_network = network_stream.map(parse_network_line).filter(lambda x: x is not None)\n",
    "\n",
    "# 按IP统计流量\n",
    "ip_traffic = parsed_network.map(lambda x: (x['ip'], x['bytes']))\n",
    "ip_totals = ip_traffic.reduceByKeyAndWindow(\n",
    "    lambda x, y: x + y,\n",
    "    9,  # 9秒窗口\n",
    "    3   # 3秒滑动\n",
    ")\n",
    "\n",
    "# 检测异常流量\n",
    "def detect_traffic_anomalies(rdd):\n",
    "    if not rdd.isEmpty():\n",
    "        traffic_data = rdd.collect()\n",
    "        \n",
    "        if traffic_data:\n",
    "            # 计算平均流量\n",
    "            total_bytes = sum(bytes_count for ip, bytes_count in traffic_data)\n",
    "            avg_bytes = total_bytes / len(traffic_data)\n",
    "            threshold = avg_bytes * 2  # 异常阈值\n",
    "            \n",
    "            print(f\"=== 网络流量监控 ===\")\n",
    "            print(f\"平均流量: {avg_bytes:.2f} bytes\")\n",
    "            print(f\"异常阈值: {threshold:.2f} bytes\")\n",
    "            \n",
    "            anomalies = [(ip, bytes_count) for ip, bytes_count in traffic_data if bytes_count > threshold]\n",
    "            \n",
    "            if anomalies:\n",
    "                print(\"检测到异常流量:\")\n",
    "                for ip, bytes_count in anomalies:\n",
    "                    print(f\"  {ip}: {bytes_count} bytes\")\n",
    "            else:\n",
    "                print(\"未检测到异常流量\")\n",
    "            print(\"=\" * 25)\n",
    "\n",
    "ip_totals.foreachRDD(detect_traffic_anomalies)\n",
    "\n",
    "# 启动网络监控\n",
    "def stop_network_streaming():\n",
    "    time.sleep(12)\n",
    "    ssc_network.stop(stopSparkContext=False)\n",
    "\n",
    "stop_thread = threading.Thread(target=stop_network_streaming)\n",
    "stop_thread.start()\n",
    "\n",
    "ssc_network.start()\n",
    "ssc_network.awaitTermination()\n",
    "\n",
    "print(\"网络流量监控练习完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 总结\n",
    "\n",
    "在本笔记本中，我们学习了：\n",
    "\n",
    "1. Spark Streaming的基本概念和DStream抽象\n",
    "2. 如何创建StreamingContext和DStream\n",
    "3. DStream的转换操作（map、filter、flatMap等）\n",
    "4. DStream的输出操作（pprint、saveAsTextFiles、foreachRDD）\n",
    "5. 有状态转换（updateStateByKey）\n",
    "6. 窗口操作（window、reduceByKeyAndWindow）\n",
    "7. 实际案例：实时销售监控系统\n",
    "8. 如何启动和停止流处理\n",
    "9. 实践练习：单词计数和网络流量监控\n",
    "\n",
    "DStream API是Spark Streaming的核心，它提供了处理实时数据流的强大功能。虽然在较新的Spark版本中推荐使用结构化流处理，但理解DStream对于掌握流处理概念仍然很重要。\n",
    "\n",
    "## 下一步\n",
    "\n",
    "接下来，我们将学习Spark的结构化流处理（Structured Streaming），它提供了更高级的API和更好的性能。请继续学习 `structured-streaming.ipynb` 笔记本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理资源\n",
    "sc.stop()\n",
    "print(\"SparkContext已停止\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}