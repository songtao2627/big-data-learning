{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎉 欢迎使用大数据学习平台！\n",
    "\n",
    "这是一个基于Docker的Apache Spark学习环境，包含：\n",
    "- Apache Spark 3.4 集群\n",
    "- Jupyter Notebook with PySpark\n",
    "- 丰富的学习材料和实践项目\n",
    "\n",
    "## 🚀 快速开始\n",
    "\n",
    "### 1. 测试Spark连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T08:46:38.169698Z",
     "iopub.status.busy": "2025-07-26T08:46:38.169326Z",
     "iopub.status.idle": "2025-07-26T08:46:40.151284Z",
     "shell.execute_reply": "2025-07-26T08:46:40.150598Z",
     "shell.execute_reply.started": "2025-07-26T08:46:38.169657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: py4j in /opt/conda/lib/python3.11/site-packages (0.10.9.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install py4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T08:46:52.992941Z",
     "iopub.status.busy": "2025-07-26T08:46:52.992648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在连接Spark集群...\n",
      "✅ Spark版本: 3.5.0\n",
      "✅ Spark应用ID: app-20250726084657-0002\n",
      "✅ Spark UI地址: http://b5cbf2657a02:4040\n",
      "\n",
      "创建测试DataFrame...\n",
      "测试DataFrame内容:\n"
     ]
    }
   ],
   "source": [
    "# 运行Spark连接测试\n",
    "exec(open('test_spark_connection.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 简单的PySpark示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 创建SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Welcome\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 创建简单的DataFrame\n",
    "data = [(\"Alice\", 25), (\"Bob\", 30), (\"Charlie\", 35)]\n",
    "df = spark.createDataFrame(data, [\"name\", \"age\"])\n",
    "\n",
    "print(\"DataFrame内容:\")\n",
    "df.show()\n",
    "\n",
    "print(f\"总行数: {df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 学习路径\n",
    "\n",
    "建议按以下顺序学习：\n",
    "\n",
    "1. **Spark基础** (`01-spark-basics/`)\n",
    "   - RDD基础操作\n",
    "   - DataFrame API\n",
    "   - Dataset API\n",
    "\n",
    "2. **Spark SQL** (`02-spark-sql/`)\n",
    "   - SQL基础查询\n",
    "   - 高级查询技巧\n",
    "   - 性能调优\n",
    "\n",
    "3. **Spark Streaming** (`03-spark-streaming/`)\n",
    "   - 流处理基础\n",
    "   - 结构化流\n",
    "   - Kafka集成\n",
    "\n",
    "4. **实践项目** (`04-projects/`)\n",
    "   - 日志分析\n",
    "   - 推荐系统\n",
    "   - 实时仪表盘\n",
    "\n",
    "### 4. 有用的链接\n",
    "\n",
    "- **Spark Master UI**: http://localhost:8080\n",
    "- **Spark应用UI**: http://localhost:4040 (运行作业时)\n",
    "- **学习路径**: [learning_path.md](learning_path.md)\n",
    "\n",
    "祝学习愉快！🎓"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
