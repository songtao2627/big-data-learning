#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Sparkè¿æ¥æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯Jupyterä¸Sparké›†ç¾¤çš„è¿æ¥
"""

from pyspark.sql import SparkSession
import sys

def test_spark_connection():
    """æµ‹è¯•Sparkè¿æ¥"""
    try:
        # åˆ›å»ºSparkSession
        print("æ­£åœ¨è¿æ¥Sparké›†ç¾¤...")
        spark = SparkSession.builder \
            .appName("SparkConnectionTest") \
            .master("spark://spark-master:7077") \
            .config("spark.sql.adaptive.enabled", "true") \
            .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
            .getOrCreate()

        # æµ‹è¯•è¿æ¥
        print(f"âœ… Sparkç‰ˆæœ¬: {spark.version}")
        print(f"âœ… Sparkåº”ç”¨ID: {spark.sparkContext.applicationId}")
        print(f"âœ… Spark UIåœ°å€: {spark.sparkContext.uiWebUrl}")
        
        # åˆ›å»ºæµ‹è¯•DataFrame
        print("\nåˆ›å»ºæµ‹è¯•DataFrame...")
        test_data = [("å¼ ä¸‰", 25, "åŒ—äº¬"), ("æå››", 30, "ä¸Šæµ·"), ("ç‹äº”", 35, "å¹¿å·")]
        columns = ["å§“å", "å¹´é¾„", "åŸå¸‚"]
        df = spark.createDataFrame(test_data, columns)
        
        print("æµ‹è¯•DataFrameå†…å®¹:")
        df.show()
        
        print(f"DataFrameè¡Œæ•°: {df.count()}")
        print(f"DataFrameåˆ—æ•°: {len(df.columns)}")
        
        # ç®€å•çš„æ•°æ®æ“ä½œæµ‹è¯•
        print("\næ‰§è¡Œç®€å•çš„æ•°æ®æ“ä½œ...")
        avg_age = df.agg({"å¹´é¾„": "avg"}).collect()[0][0]
        print(f"å¹³å‡å¹´é¾„: {avg_age:.1f}")
        
        # åœæ­¢SparkSession
        spark.stop()
        print("\nğŸ‰ Sparkè¿æ¥æµ‹è¯•æˆåŠŸï¼")
        return True
        
    except Exception as e:
        print(f"âŒ Sparkè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

if __name__ == "__main__":
    test_spark_connection()
