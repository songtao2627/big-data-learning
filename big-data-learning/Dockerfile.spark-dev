# åŸºäº Bitnami Spark é•œåƒæ„å»ºå¼€å‘ç¯å¢ƒ
FROM bitnami/spark:3.4

# åˆ‡æ¢åˆ° root ç”¨æˆ·è¿›è¡Œå®‰è£…
USER root

# é…ç½®å›½å†…è½¯ä»¶æºåŠ é€Ÿ
RUN sed -i 's/deb.debian.org/mirrors.aliyun.com/g' /etc/apt/sources.list && \
    sed -i 's/security.debian.org/mirrors.aliyun.com/g' /etc/apt/sources.list

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    curl \
    wget \
    vim \
    git \
    python3-pip \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# é…ç½® pip å›½å†…æºï¼ˆå…¨å±€é…ç½®ï¼‰
RUN pip3 config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple

# å®‰è£… Python åŒ…ï¼ˆä½¿ç”¨ root ç”¨æˆ·å®‰è£…åˆ°ç³»ç»Ÿï¼‰
RUN pip3 install --no-cache-dir \
    jupyter \
    jupyterlab \
    pandas \
    matplotlib \
    seaborn \
    plotly \
    numpy \
    scipy \
    scikit-learn \
    requests \
    beautifulsoup4 \
    py4j==0.10.9.7 \
    findspark

# åˆ‡æ¢å› spark ç”¨æˆ·
USER 1001

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /opt/bitnami/spark

# åˆ›å»ºå¿…è¦çš„ç›®å½•
RUN mkdir -p /opt/bitnami/spark/notebooks && \
    ls -la /opt/bitnami/spark/notebooks

# åˆ‡æ¢å› root ç”¨æˆ·åˆ›å»ºæ–‡ä»¶
USER root

# åˆ›å»º PySpark åˆå§‹åŒ–æ–‡ä»¶ï¼ˆä½¿ç”¨ heredoc è¯­æ³•ï¼‰
RUN cat << 'EOF' > /opt/bitnami/spark/notebooks/pyspark_init.py
from pyspark.sql import SparkSession

def create_spark_session(app_name="SparkLearning"):
    spark = SparkSession.builder \
        .appName(app_name) \
        .master("spark://spark-master:7077") \
        .config("spark.executor.memory", "1g") \
        .config("spark.driver.memory", "1g") \
        .getOrCreate()
    spark.sparkContext.setLogLevel("WARN")
    return spark

# è‡ªåŠ¨åˆ›å»º Spark ä¼šè¯
print("æ­£åœ¨åˆå§‹åŒ– Spark ä¼šè¯...")
try:
    spark = create_spark_session()
    print("âœ… Spark ä¼šè¯åˆ›å»ºæˆåŠŸï¼")
    print(f"Spark ç‰ˆæœ¬: {spark.version}")
    print(f"Master URL: {spark.sparkContext.master}")
except Exception as e:
    print(f"âŒ Spark ä¼šè¯åˆ›å»ºå¤±è´¥: {e}")
    print("è¯·æ£€æŸ¥ Spark é›†ç¾¤æ˜¯å¦æ­£å¸¸è¿è¡Œ")
EOF

# è®¾ç½® Jupyter å¯åŠ¨è„šæœ¬ï¼ˆä½¿ç”¨ heredoc è¯­æ³•ï¼‰
RUN cat << 'EOF' > /opt/bitnami/spark/start-jupyter.sh
#!/bin/bash
echo "ğŸš€ å¯åŠ¨ Jupyter Lab..."
jupyter lab \
    --ip=0.0.0.0 \
    --port=8888 \
    --no-browser \
    --allow-root \
    --notebook-dir=/opt/bitnami/spark/notebooks \
    --ServerApp.token=spark-learning \
    --ServerApp.password="" \
    --ServerApp.disable_check_xsrf=True \
    --ServerApp.allow_origin="*" \
    --ServerApp.terminals_enabled=True
EOF

# ç¡®ä¿è„šæœ¬æœ‰æ­£ç¡®çš„Unixæ¢è¡Œç¬¦å’Œæ‰§è¡Œæƒé™
RUN sed -i 's/\r$//' /opt/bitnami/spark/start-jupyter.sh && \
    chmod +x /opt/bitnami/spark/start-jupyter.sh

# æ·»åŠ æ›´è¯¦ç»†çš„æ£€æŸ¥æ­¥éª¤
RUN if [ ! -f /opt/bitnami/spark/start-jupyter.sh ]; then \
        echo "Error: start-jupyter.sh not found"; \
        exit 1; \
    else \
        echo "start-jupyter.sh found"; \
        echo "Script content:"; \
        cat /opt/bitnami/spark/start-jupyter.sh; \
        echo "File format check:"; \
        file /opt/bitnami/spark/start-jupyter.sh || echo "file command not available"; \
    fi && \
    if [ ! -d /opt/bitnami/spark/notebooks ]; then \
        echo "Error: notebooks directory not found"; \
        exit 1; \
    else \
        echo "notebooks directory found"; \
    fi

# ä¿®æ”¹æ–‡ä»¶æ‰€æœ‰æƒ
RUN chown -R 1001:1001 /opt/bitnami/spark/notebooks /opt/bitnami/spark/start-jupyter.sh

# åˆ‡æ¢å› spark ç”¨æˆ·
USER 1001

# æš´éœ²ç«¯å£
EXPOSE 8888 4040 4041

# è®¾ç½®å¯åŠ¨å‘½ä»¤
CMD ["/opt/bitnami/spark/start-jupyter.sh"]