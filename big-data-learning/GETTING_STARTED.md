# ğŸš€ å¿«é€Ÿä¸Šæ‰‹æŒ‡å—

## ğŸ“‹ ç¯å¢ƒè¦æ±‚

- **Docker Desktop** (å¿…éœ€)
- **8GB+ å†…å­˜** (æ¨è)
- **Windows 10/11, macOS, æˆ– Linux**

## âš¡ ä¸€åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

```powershell
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd big-data-learning

# 2. ä¸€é”®å¯åŠ¨å¹¶æµ‹è¯•
.\quick_container_start.ps1 -Test

# 3. å¼€å§‹å­¦ä¹ 
# è®¿é—® http://localhost:8888 (token: spark-learning)
```

å°±è¿™ä¹ˆç®€å•ï¼ğŸ‰

## ğŸ¯ æ¨èå­¦ä¹ è·¯å¾„

### ç¬¬ä¸€æ­¥ï¼šéªŒè¯ç¯å¢ƒ
```powershell
.\quick_container_start.ps1 -Test
```
ç¡®ä¿æ‰€æœ‰æœåŠ¡æ­£å¸¸è¿è¡Œï¼Œç½‘ç»œè¿é€šæ€§è‰¯å¥½ã€‚

### ç¬¬äºŒæ­¥ï¼šæ‰“å¼€ Jupyter Lab
1. è®¿é—® http://localhost:8888
2. è¾“å…¥ token: `spark-learning`
3. æ‰“å¼€ `container-spark-demo.ipynb`

### ç¬¬ä¸‰æ­¥ï¼šæŒ‰é¡ºåºå­¦ä¹ 
1. **Spark åŸºç¡€** (`notebooks/01-spark-basics/`)
   - RDD åŸºç¡€æ“ä½œ
   - DataFrame API
   - Dataset API

2. **Spark SQL** (`notebooks/02-spark-sql/`)
   - SQL åŸºç¡€æŸ¥è¯¢
   - é«˜çº§æŸ¥è¯¢æŠ€å·§
   - æ€§èƒ½è°ƒä¼˜

3. **æµå¤„ç†** (`notebooks/03-spark-streaming/`)
   - DStream åŸºç¡€
   - Structured Streaming
   - Kafka é›†æˆ

4. **å®æˆ˜é¡¹ç›®** (`notebooks/04-projects/`)
   - æ¨èç³»ç»Ÿ
   - æ—¥å¿—åˆ†æ
   - å®æ—¶ä»ªè¡¨æ¿

## ğŸ› ï¸ å¸¸ç”¨æ“ä½œ

### ç¯å¢ƒç®¡ç†
```powershell
# å¯åŠ¨ç¯å¢ƒ
.\quick_container_start.ps1

# æ¸…ç†é‡å¯
.\quick_container_start.ps1 -Clean

# åœæ­¢ç¯å¢ƒ
docker-compose down

# æŸ¥çœ‹çŠ¶æ€
docker-compose ps
```

### å¼€å‘æ“ä½œ
```powershell
# è¿›å…¥å¼€å‘å®¹å™¨
docker exec -it spark-dev bash

# è¿è¡Œ Python è„šæœ¬
docker exec -it spark-dev python3 your_script.py

# ä½¿ç”¨ spark-submit
docker exec -it spark-dev spark-submit your_app.py

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f spark-dev
```

### æµ‹è¯•å’Œè¯Šæ–­
```powershell
# ç¯å¢ƒæµ‹è¯•
docker exec -it spark-dev python3 test_container_environment.py

# ç½‘ç»œæµ‹è¯•
docker exec -it spark-dev python3 test_network_connectivity.py

# æŸ¥çœ‹ Spark UI
# http://localhost:8080 (é›†ç¾¤çŠ¶æ€)
# http://localhost:4040 (åº”ç”¨çŠ¶æ€)
```

## ğŸ“š é‡è¦æ–‡æ¡£

| æ–‡æ¡£ | ç”¨é€” |
|------|------|
| [SCRIPTS_OVERVIEW.md](SCRIPTS_OVERVIEW.md) | è„šæœ¬æ€»è§ˆå’Œä½¿ç”¨æŒ‡å— â­ |
| [CONTAINER_DEV_GUIDE.md](CONTAINER_DEV_GUIDE.md) | å®¹å™¨å¼€å‘è¯¦ç»†æŒ‡å— |
| [SCRIPTS_COMPARISON.md](SCRIPTS_COMPARISON.md) | å¯åŠ¨è„šæœ¬å¯¹æ¯”è¯´æ˜ |
| [NETWORK_TROUBLESHOOTING.md](NETWORK_TROUBLESHOOTING.md) | ç½‘ç»œé—®é¢˜æ’é™¤ |
| [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md) | é¡¹ç›®ç»“æ„è¯´æ˜ |
| [notebooks/learning_path.md](notebooks/learning_path.md) | å­¦ä¹ è·¯å¾„è§„åˆ’ |

## ğŸ”§ ä¸‰ä¸ªå¯åŠ¨è„šæœ¬çš„åŒºåˆ«

| ç‰¹æ€§ | `quick_container_start.ps1` | `start_dev_environment.ps1` | `start_environment.ps1` |
|------|---------------------------|----------------------------|------------------------|
| **ç›®æ ‡ç”¨æˆ·** | æ–°æ‰‹ â­ | é«˜çº§ç”¨æˆ· | ä¸“ä¸šç”¨æˆ· |
| **å¼€å‘å®¹å™¨** | âœ… åŒ…å« | âœ… åŒ…å« | âŒ ä¸åŒ…å« |
| **Jupyter Lab** | âœ… 8888ç«¯å£ | âœ… 8888ç«¯å£ | âŒ æ—  |
| **å¯é€‰ç»„ä»¶** | âŒ ä¸æ”¯æŒ | âœ… Kafka/ES/Kibana | âœ… Kafka/ES/Kibana |
| **è‡ªåŠ¨æµ‹è¯•** | âœ… -Testå‚æ•° | âŒ æ—  | âŒ æ—  |

### é€‰æ‹©å»ºè®®
- **90% çš„ç”¨æˆ·**: ä½¿ç”¨ `quick_container_start.ps1` â­
- **éœ€è¦é«˜çº§åŠŸèƒ½**: ä½¿ç”¨ `start_dev_environment.ps1`
- **æœ¬åœ°å¼€å‘ä¸“å®¶**: ä½¿ç”¨ `start_environment.ps1`

### é«˜çº§åŠŸèƒ½ç¤ºä¾‹
```powershell
# å¯åŠ¨æµå¤„ç†ç»„ä»¶ (Kafka)
.\scripts\start_dev_environment.ps1 -Streaming

# å¯åŠ¨åˆ†æç»„ä»¶ (Elasticsearch/Kibana)
.\scripts\start_dev_environment.ps1 -Analytics

# å¯åŠ¨æ‰€æœ‰ç»„ä»¶
.\scripts\start_dev_environment.ps1 -All

# ä»…å¯åŠ¨é›†ç¾¤ (æœ¬åœ°å¼€å‘)
.\scripts\start_environment.ps1
```

## â“ å¸¸è§é—®é¢˜

### Q: å¯åŠ¨å¤±è´¥æ€ä¹ˆåŠï¼Ÿ
```powershell
# 1. æ£€æŸ¥ Docker æ˜¯å¦è¿è¡Œ
docker version

# 2. æ¸…ç†é‡å¯
.\quick_container_start.ps1 -Clean -Test

# 3. æŸ¥çœ‹æ—¥å¿—
docker-compose logs
```

### Q: ç½‘ç»œè¿æ¥é—®é¢˜ï¼Ÿ
```powershell
# è¿è¡Œç½‘ç»œè¯Šæ–­
docker exec -it spark-dev python3 test_network_connectivity.py

# æŸ¥çœ‹ç½‘ç»œæ•…éšœæ’é™¤æŒ‡å—
# é˜…è¯» NETWORK_TROUBLESHOOTING.md
```

### Q: æ€§èƒ½é—®é¢˜ï¼Ÿ
- ç¡®ä¿ Docker Desktop åˆ†é…è¶³å¤Ÿå†…å­˜ (8GB+)
- å…³é—­ä¸å¿…è¦çš„åº”ç”¨ç¨‹åº
- æ£€æŸ¥ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ

### Q: æƒ³è¦è‡ªå®šä¹‰é…ç½®ï¼Ÿ
- ä¿®æ”¹ `docker-compose.yml` è°ƒæ•´èµ„æºé…ç½®
- ç¼–è¾‘ `scripts/spark-defaults.conf` ä¼˜åŒ– Spark å‚æ•°
- æŸ¥çœ‹ `CONTAINER_DEV_GUIDE.md` äº†è§£è¯¦ç»†é…ç½®

## ğŸ‰ å¼€å§‹å­¦ä¹ 

ç°åœ¨ä½ å·²ç»å‡†å¤‡å¥½å¼€å§‹ Spark å­¦ä¹ ä¹‹æ—…äº†ï¼

1. **è¿è¡Œ**: `.\quick_container_start.ps1 -Test`
2. **è®¿é—®**: http://localhost:8888
3. **å­¦ä¹ **: ä» `container-spark-demo.ipynb` å¼€å§‹
4. **å®è·µ**: å®Œæˆå„ä¸ªå­¦ä¹ æ¨¡å—å’Œé¡¹ç›®

ç¥ä½ å­¦ä¹ æ„‰å¿«ï¼ğŸš€

## ğŸ’¡ å°è´´å£«

- ä½¿ç”¨ `Ctrl+C` å¯ä»¥åœæ­¢æ­£åœ¨è¿è¡Œçš„è„šæœ¬
- Jupyter Lab æ”¯æŒå¤šç§æ–‡ä»¶æ ¼å¼ç¼–è¾‘
- å¯ä»¥åœ¨å®¹å™¨å†…å®‰è£…é¢å¤–çš„ Python åŒ…
- å®šæœŸè¿è¡Œæµ‹è¯•è„šæœ¬ç¡®ä¿ç¯å¢ƒæ­£å¸¸
- é‡åˆ°é—®é¢˜å…ˆæŸ¥çœ‹ç›¸å…³æ–‡æ¡£ï¼Œå¤§éƒ¨åˆ†é—®é¢˜éƒ½æœ‰è§£å†³æ–¹æ¡ˆ