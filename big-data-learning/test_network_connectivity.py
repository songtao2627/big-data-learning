#!/usr/bin/env python3
"""
Docker å®¹å™¨ç½‘ç»œè¿é€šæ€§æµ‹è¯•è„šæœ¬
æµ‹è¯•å„å®¹å™¨é—´çš„ç½‘ç»œé€šä¿¡æ˜¯å¦æ­£å¸¸
"""

import socket
import subprocess
import sys
import time
from datetime import datetime

def print_section(title):
    print(f"\n{'='*60}")
    print(f"ğŸ” {title}")
    print('='*60)

def test_dns_resolution():
    """æµ‹è¯• DNS è§£æ"""
    print_section("DNS è§£ææµ‹è¯•")
    
    hosts = [
        "spark-master",
        "spark-worker-1", 
        "spark-worker-2",
        "spark-dev",
        "zookeeper",
        "kafka",
        "elasticsearch",
        "kibana"
    ]
    
    for host in hosts:
        try:
            ip = socket.gethostbyname(host)
            print(f"âœ… {host:15} -> {ip}")
        except socket.gaierror:
            print(f"âŒ {host:15} -> DNS è§£æå¤±è´¥")

def test_port_connectivity():
    """æµ‹è¯•ç«¯å£è¿é€šæ€§"""
    print_section("ç«¯å£è¿é€šæ€§æµ‹è¯•")
    
    # å®šä¹‰æœåŠ¡å’Œç«¯å£
    services = [
        ("spark-master", 7077, "Spark Master"),
        ("spark-master", 8080, "Spark Master UI"),
        ("spark-worker-1", 8881, "Spark Worker 1"),
        ("spark-worker-1", 8081, "Spark Worker 1 UI"),
        ("spark-worker-2", 8882, "Spark Worker 2"),
        ("spark-worker-2", 8081, "Spark Worker 2 UI"),
        ("spark-dev", 8888, "Jupyter Lab"),
        ("zookeeper", 2181, "Zookeeper"),
        ("kafka", 29092, "Kafka Internal"),
        ("elasticsearch", 9200, "Elasticsearch"),
        ("kibana", 5601, "Kibana")
    ]
    
    for host, port, service in services:
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(3)
            result = sock.connect_ex((host, port))
            sock.close()
            
            if result == 0:
                print(f"âœ… {service:20} {host}:{port} - è¿æ¥æˆåŠŸ")
            else:
                print(f"âŒ {service:20} {host}:{port} - è¿æ¥å¤±è´¥")
                
        except Exception as e:
            print(f"âŒ {service:20} {host}:{port} - æµ‹è¯•å¼‚å¸¸: {str(e)}")

def test_ping_connectivity():
    """æµ‹è¯• ping è¿é€šæ€§"""
    print_section("Ping è¿é€šæ€§æµ‹è¯•")
    
    hosts = ["spark-master", "spark-worker-1", "spark-worker-2"]
    
    for host in hosts:
        try:
            # ä½¿ç”¨ ping å‘½ä»¤æµ‹è¯•è¿é€šæ€§
            result = subprocess.run(
                ["ping", "-c", "2", host], 
                capture_output=True, 
                text=True, 
                timeout=10
            )
            
            if result.returncode == 0:
                print(f"âœ… {host:15} - Ping æˆåŠŸ")
            else:
                print(f"âŒ {host:15} - Ping å¤±è´¥")
                
        except subprocess.TimeoutExpired:
            print(f"âŒ {host:15} - Ping è¶…æ—¶")
        except Exception as e:
            print(f"âŒ {host:15} - Ping å¼‚å¸¸: {str(e)}")

def test_spark_cluster_communication():
    """æµ‹è¯• Spark é›†ç¾¤é€šä¿¡"""
    print_section("Spark é›†ç¾¤é€šä¿¡æµ‹è¯•")
    
    try:
        from pyspark.sql import SparkSession
        
        print("ğŸ”— åˆ›å»º Spark ä¼šè¯...")
        spark = SparkSession.builder \
            .appName("NetworkConnectivityTest") \
            .master("spark://spark-master:7077") \
            .config("spark.executor.memory", "512m") \
            .config("spark.driver.memory", "512m") \
            .getOrCreate()
        
        spark.sparkContext.setLogLevel("WARN")
        
        print(f"âœ… Spark ç‰ˆæœ¬: {spark.version}")
        print(f"âœ… Master URL: {spark.sparkContext.master}")
        print(f"âœ… åº”ç”¨ ID: {spark.sparkContext.applicationId}")
        
        # æµ‹è¯•ç®€å•çš„åˆ†å¸ƒå¼æ“ä½œ
        print("\nğŸ§® æµ‹è¯•åˆ†å¸ƒå¼è®¡ç®—...")
        rdd = spark.sparkContext.parallelize(range(100), 4)
        result = rdd.map(lambda x: x * x).reduce(lambda a, b: a + b)
        print(f"âœ… åˆ†å¸ƒå¼è®¡ç®—ç»“æœ: {result}")
        
        # è·å– Executor ä¿¡æ¯
        executors = spark.sparkContext.statusTracker().getExecutorInfos()
        print(f"âœ… æ´»è·ƒ Executor æ•°é‡: {len(executors)}")
        
        for executor in executors:
            print(f"   Executor {executor.executorId}: {executor.host}")
        
        spark.stop()
        print("âœ… Spark é›†ç¾¤é€šä¿¡æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âŒ Spark é›†ç¾¤é€šä¿¡å¤±è´¥: {str(e)}")
        return False

def test_network_performance():
    """æµ‹è¯•ç½‘ç»œæ€§èƒ½"""
    print_section("ç½‘ç»œæ€§èƒ½æµ‹è¯•")
    
    hosts = ["spark-master", "spark-worker-1", "spark-worker-2"]
    
    for host in hosts:
        try:
            start_time = time.time()
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(5)
            sock.connect((host, 7077))
            sock.close()
            end_time = time.time()
            
            latency = (end_time - start_time) * 1000
            print(f"âœ… {host:15} - è¿æ¥å»¶è¿Ÿ: {latency:.2f}ms")
            
        except Exception as e:
            print(f"âŒ {host:15} - æ€§èƒ½æµ‹è¯•å¤±è´¥: {str(e)}")

def show_network_info():
    """æ˜¾ç¤ºç½‘ç»œä¿¡æ¯"""
    print_section("ç½‘ç»œé…ç½®ä¿¡æ¯")
    
    try:
        # æ˜¾ç¤ºå®¹å™¨ IP åœ°å€
        result = subprocess.run(
            ["hostname", "-I"], 
            capture_output=True, 
            text=True
        )
        if result.returncode == 0:
            print(f"å½“å‰å®¹å™¨ IP: {result.stdout.strip()}")
        
        # æ˜¾ç¤ºè·¯ç”±ä¿¡æ¯
        result = subprocess.run(
            ["ip", "route"], 
            capture_output=True, 
            text=True
        )
        if result.returncode == 0:
            print(f"\nè·¯ç”±ä¿¡æ¯:")
            print(result.stdout)
            
    except Exception as e:
        print(f"è·å–ç½‘ç»œä¿¡æ¯å¤±è´¥: {str(e)}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ Docker å®¹å™¨ç½‘ç»œè¿é€šæ€§æµ‹è¯•")
    print(f"â° æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ˜¾ç¤ºç½‘ç»œä¿¡æ¯
    show_network_info()
    
    # æ‰§è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ("DNS è§£æ", test_dns_resolution),
        ("ç«¯å£è¿é€šæ€§", test_port_connectivity),
        ("Ping è¿é€šæ€§", test_ping_connectivity),
        ("ç½‘ç»œæ€§èƒ½", test_network_performance),
        ("Spark é›†ç¾¤é€šä¿¡", test_spark_cluster_communication)
    ]
    
    results = {}
    
    for test_name, test_func in tests:
        try:
            print(f"\nğŸ” å¼€å§‹ {test_name} æµ‹è¯•...")
            result = test_func()
            results[test_name] = result if result is not None else True
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {str(e)}")
            results[test_name] = False
    
    # æ€»ç»“æŠ¥å‘Š
    print_section("æµ‹è¯•æ€»ç»“")
    
    passed = sum(1 for result in results.values() if result)
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"  {test_name:15}: {status}")
    
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰ç½‘ç»œæµ‹è¯•é€šè¿‡ï¼å®¹å™¨é—´é€šä¿¡æ­£å¸¸")
    else:
        print("âš ï¸  éƒ¨åˆ†ç½‘ç»œæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œé…ç½®")
        print("\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print("  1. æ£€æŸ¥å®¹å™¨çŠ¶æ€: docker-compose ps")
        print("  2. æ£€æŸ¥ç½‘ç»œ: docker network ls")
        print("  3. é‡å¯ç¯å¢ƒ: docker-compose down && docker-compose up -d")

if __name__ == "__main__":
    main()